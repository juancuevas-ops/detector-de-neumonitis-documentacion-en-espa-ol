{"cells":[{"metadata":{"_cell_guid":"d14b5cfa-a0e3-4e14-897e-16b0cc186c0c","_uuid":"7c448bc30163ab2af6f6ffcbd1762915d70ec327"},"cell_type":"markdown","source":"# detectando neumonia en imagenes de rayos x","execution_count":null},{"metadata":{"_cell_guid":"688d9d6c-b38e-4121-8bc0-33ffccc757bd","_uuid":"5b08e4c16f36b20700a9334f4a8f7bfb1906105f"},"cell_type":"markdown","source":"Using data from http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5","execution_count":null},{"metadata":{"_cell_guid":"b5fec7be-5525-4c45-8f9c-cb4b2c112be6","_uuid":"c9f7d8da6a863a9d9bb3050e2aa4745ec26dd54a"},"cell_type":"markdown","source":"\nFigura S6. Ejemplos ilustrativos de radiografías de tórax en pacientes con neumonía, relacionadas con la Figura 6 La radiografía de tórax normal (panel izquierdo) muestra pulmones claros sin áreas de opacificación anormal en la imagen. La neumonía bacteriana (media) generalmente presenta una consolidación lobular focal, en este caso en el lóbulo superior derecho (flechas blancas), mientras que la neumonía viral (derecha) se manifiesta con un patrón \"intersticial\" más difuso en ambos pulmones. http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5\ncreado por pool monkey y documentado en español por juan alejandro cuevas vasquez\n\n# DOCUMENTACION EN ESPAÑOL.","execution_count":null},{"metadata":{"_cell_guid":"8ac5aba9-de61-4c1a-9197-0806bcd223b5","_uuid":"7f9547358c9cebf0a42166738c7dff19b16ff916"},"cell_type":"markdown","source":"*Step 1: Import Modules*","execution_count":null},{"metadata":{"_kg_hide-output":true,"_cell_guid":"42b35245-93b6-45ed-bcf8-d9ff22473269","_kg_hide-input":true,"_uuid":"3d3bc91774b6b395666c22dc2cca97af6d5dcbe3","trusted":true,"collapsed":true},"cell_type":"code","source":"import os\nfrom glob import glob\nimport matplotlib.pyplot as plt\nimport random\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.gridspec as gridspec\nimport seaborn as sns\nimport zlib\nimport itertools\nimport sklearn\nimport itertools\nimport scipy\nimport skimage\nfrom skimage.transform import resize\nimport csv\nfrom tqdm import tqdm\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split, learning_curve,KFold,cross_val_score,StratifiedKFold\nfrom sklearn.utils import class_weight\nfrom sklearn.metrics import confusion_matrix\nimport keras\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, MaxPool2D, BatchNormalization\nfrom keras.utils import np_utils\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import models, layers, optimizers\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.utils import class_weight\nfrom keras.optimizers import SGD, RMSprop, Adam, Adagrad, Adadelta, RMSprop\nfrom keras.models import Sequential, model_from_json\nfrom keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom keras import backend as K\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\n#from keras.applications.mobilenet import MobileNet\n#from sklearn.metrics import roc_auc_score\n#from sklearn.metrics import roc_curve\n#from sklearn.metrics import auc\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"59dcc7b7-740e-4ecf-a8ac-c86e66ea3511","_uuid":"be534235b529040019854353c2f3a373300cfb20"},"cell_type":"markdown","source":"*Step 2: Load Data*","execution_count":null},{"metadata":{"_cell_guid":"86a1fb25-c9b2-41fe-8bc3-01d91f7054bb","_uuid":"22c127e3183a316ca314946688e21db95a7dc4ca","trusted":true,"collapsed":true},"cell_type":"code","source":"train_dir = \"../input/chest-xray-pneumonia/chest_xray/chest_xray/train/\" # se adjuntan los datos para el analisis se deben extraer del archivo zip en \ntest_dir =  \"../input/chest-xray-pneumonia/chest_xray/chest_xray/test/\" # la misma carpeta que creas el notebook\ndef get_data(folder): # se define la funcion get_data con parametro folder\n    X = []# se declaran la variables x,y\n    y = []\n    for folderName in os.listdir(folder):#El método listdir () devuelve una lista que contiene los nombres de las entradas en el directorio dado por la ruta\n        if not folderName.startswith('.'):#este metodo retorna un verdadero si un string comienza con el especifico prefix(string)\n            if folderName in ['NORMAL']:#en esta linea condiciona a normal sin neumonia a nivel 0\n                label = 0\n            elif folderName in ['PNEUMONIA']:#condiciona a neumonia al nivel 1 de lo contrario al nivel 2\n                label = 1\n            else:\n                label = 2\n            for image_filename in tqdm(os.listdir(folder + folderName)):\n                img_file = cv2.imread(folder + folderName + '/' + image_filename)#reconocimiento de imagen con opencv\n                if img_file is not None:\n                    img_file = skimage.transform.resize(img_file, (150, 150, 3))#Cambiar el tamaño de la imagen para que coincida con tamaño entre parentesis\n                    #img_file = scipy.misc.imresize(arr=img_file, size=(150, 150, 3))\n                    img_arr = np.asarray(img_file)\n                    X.append(img_arr)#Agrega su argumento como un elemento único al final de una lista.\n                    y.append(label)\n    X = np.asarray(X)#creacion de matriz\n    y = np.asarray(y)\n    return X,y\nX_train, y_train = get_data(train_dir)#\"../input/chest-xray-pneumonia/chest_xray/chest_xray/train/ estos datos seran entrenados\nX_test, y_test= get_data(test_dir)#../input/chest-xray-pneumonia/chest_xray/chest_xray/test/ estos datos seran testeados\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nfrom keras.utils.np_utils import to_categorical\ny_trainHot = to_categorical(y_train, num_classes = 2) #numero de clases  de entrenamiento a categoria \ny_testHot = to_categorical(y_test, num_classes = 2)#numero de clases de testeo a categoria","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9697e49e-842c-4036-ae9f-641046758573","_uuid":"6a6b491f3ab910d04a2e7053eb8fb50eac2713c3"},"cell_type":"markdown","source":"*Step 3: Vizualize Data*","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a8175a28-50e7-4ef0-bdce-7d45de647677","_uuid":"23b61840058209bb797359e6b9eed686b5ecf3ac"},"cell_type":"markdown","source":"\nLos valores de píxel mínimo / máximo ya están escalados entre 0 y 1","execution_count":null},{"metadata":{"_cell_guid":"1abb596c-5c13-4d48-aaf2-d4683f822511","_uuid":"eb614459b47542a02b0bf9241d778922d6800a88","trusted":true,"collapsed":true},"cell_type":"code","source":"def plotHistogram(a):\n    \"\"\"\n    Plot histogram of RGB Pixel Intensities\n    \"\"\"\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)              #HISTOGRAMA DE GRUPO DE DATOS ENTRENAMIENTO\n    plt.imshow(a)\n    plt.axis('off')\n    histo = plt.subplot(1,2,2)\n    histo.set_ylabel('Count')\n    histo.set_xlabel('Pixel Intensity')\n    n_bins = 30\n    plt.hist(a[:,:,0].flatten(), bins= n_bins, lw = 0, color='r', alpha=0.5);\n    plt.hist(a[:,:,1].flatten(), bins= n_bins, lw = 0, color='g', alpha=0.5);\n    plt.hist(a[:,:,2].flatten(), bins= n_bins, lw = 0, color='b', alpha=0.5);\nplotHistogram(X_train[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"_cell_guid":"ee1a586a-7c7d-4e05-9341-5b7405849492","_uuid":"5328b63c34231563f8bfc2229f8b6efe76291c0e"},"cell_type":"markdown","source":"3 rayos x de la  categoria \"No neumonia\"","execution_count":null},{"metadata":{"_cell_guid":"ca9e3937-1a11-423a-9615-64e56220225a","_uuid":"1d8945520f8763653c798ccfa7a7e270367cf09f","trusted":true,"collapsed":true},"cell_type":"code","source":"multipleImages = glob('../input/chest-xray-pneumonia/chest_xray/chest_xray/train/NORMAL/**')\ndef plotThreeImages(images):\n    r = random.sample(images, 3)\n    plt.figure(figsize=(16,16))\n    plt.subplot(131)\n    plt.imshow(cv2.imread(r[0]))\n    plt.subplot(132)\n    plt.imshow(cv2.imread(r[1])) #MUETRA DE DATOS SIN NEUMONIA\n    plt.subplot(133)\n    plt.imshow(cv2.imread(r[2])); \nplotThreeImages(multipleImages)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"199e4466-a943-4de8-892e-c9ba068265c8","_uuid":"16f6d7087f9523d1633ecf65985c091ce8d64ba7"},"cell_type":"markdown","source":"20 images from category \"No Pneumonia\"","execution_count":null},{"metadata":{"_cell_guid":"cd7271b9-db7e-4077-b7e0-82a7d182a223","_uuid":"2be42c9523cd6e2434a43ac5515736101971aa9e","trusted":true,"collapsed":true},"cell_type":"code","source":"print(\"sin neumonia\")\nmultipleImages = glob('../input/chest-xray-pneumonia/chest_xray/chest_xray/train/NORMAL/**')\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)             #20 imagenes normales sin neumonia\nfor l in multipleImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (128, 128)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"ec88b5d9-327f-4089-b3aa-3c4045d76025","_uuid":"472d6a6c0a604aac9017b03bf8e885adc19aa90c"},"cell_type":"markdown","source":"20 images de la  categoria \"si Pneumonia\"","execution_count":null},{"metadata":{"_cell_guid":"f5334023-e1cc-4b1e-a8fc-64237115e88f","_uuid":"e8cfa379815959d01f5d78113e4ebd6e2d5f4084","trusted":true,"collapsed":true},"cell_type":"code","source":"print(\"con neumonia\")\nmultipleImages = glob('../input/chest-xray-pneumonia/chest_xray/chest_xray/train/PNEUMONIA/**')\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)         #muestra de imagenes con neumonia\nfor l in multipleImages[:25]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (128, 128)) \n    plt.subplot(5, 5, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"acafe27f-6c13-4091-9ce0-907c5784eb79","_uuid":"6384bf60c740fc5cc97c90c6bb4a170e294210b2","trusted":true,"collapsed":true},"cell_type":"code","source":"map_characters = {0: 'sin neumonia', 1: 'con neumonia'}\ndict_characters=map_characters\nimport seaborn as sns\ndf = pd.DataFrame()\ndf[\"labels\"]=y_train            #GRAFICO EN DONDE 0=SIN NEUMONIA Y 1=CON NEUMONIA\nlab = df['labels']\ndist = lab.value_counts()\nsns.countplot(lab)\nprint(dict_characters)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"9414e78c-08b4-4c5c-b8df-73240e7c1350","_uuid":"83b4d12d206885ead7b84145c25027942a0f5b65"},"cell_type":"markdown","source":"*Step 4: Define Helper Functions*","execution_count":null},{"metadata":{"collapsed":true,"_cell_guid":"5c2b5fc4-e1af-4dfe-a928-8a8076c73d59","_uuid":"992129dbd3c7695bdd2e2497a6a56da0227c8c0d","trusted":true},"cell_type":"code","source":"#Funciones auxiliares Curvas de aprendizaje y matriz de confusión\n\nfrom keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nclass MetricsCheckpoint(Callback):\n    \"\"\"Callback that saves metrics after each epoch\"\"\"\n    def __init__(self, savepath):\n        super(MetricsCheckpoint, self).__init__()\n        self.savepath = savepath\n        self.history = {}\n    def on_epoch_end(self, epoch, logs=None):\n        for k, v in logs.items():\n            self.history.setdefault(k, []).append(v)\n        np.save(self.savepath, self.history)\n\ndef plotKerasLearningCurve():\n    plt.figure(figsize=(10,5))\n    metrics = np.load('logs.npy')[()]\n    filt = ['acc'] # try to add 'loss' to see the loss learning curve\n    for k in filter(lambda x : np.any([kk in x for kk in filt]), metrics.keys()):\n        l = np.array(metrics[k])\n        plt.plot(l, c= 'r' if 'val' not in k else 'b', label='val' if 'val' in k else 'train')\n        x = np.argmin(l) if 'loss' in k else np.argmax(l)\n        y = l[x]\n        plt.scatter(x,y, lw=0, alpha=0.25, s=100, c='r' if 'val' not in k else 'b')\n        plt.text(x, y, '{} = {:.4f}'.format(x,y), size='15', color= 'r' if 'val' not in k else 'b')   \n    plt.legend(loc=4)\n    plt.axis([0, None, None, None]);\n    plt.grid()\n    plt.xlabel('Number of epochs')\n    plt.ylabel('Accuracy')\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ndef plot_learning_curve(history):\n    plt.figure(figsize=(8,8))\n    plt.subplot(1,2,1)\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./accuracy_curve.png')\n    plt.subplot(1,2,2)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.savefig('./loss_curve.png')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6d9c6929-3f64-4d4e-a82b-362602641156","_uuid":"46be241c508bd8f733fd41b84fa0d4d12ff67b33"},"cell_type":"markdown","source":"*Step 5: Evaluate Classification Models*","execution_count":null},{"metadata":{"_cell_guid":"3dac612a-0543-47a7-b9be-9a45820b0473","_uuid":"7bb6dff5a30e1644bbfffa0a7c7b5992df5a494c"},"cell_type":"markdown","source":"Transfer learning w/ VGG16 Convolutional Network","execution_count":null},{"metadata":{"collapsed":true,"scrolled":true,"_cell_guid":"da473dc4-7e79-4be0-97aa-c7cca6e8aa43","_uuid":"1b8d8acad18ea6c063c61c50d84c5c65f8678b21","trusted":true},"cell_type":"code","source":"map_characters1 = {0: 'sin neumonia', 1: 'con neumonia'}\nclass_weight1 = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)\nweight_path1 = '../input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nweight_path2 = '../input/keras-pretrained-models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\npretrained_model_1 = VGG16(weights = weight_path1, include_top=False, input_shape=(150, 150, 3))\npretrained_model_2 = InceptionV3(weights = weight_path2, include_top=False, input_shape=(150, 150, 3))\noptimizer1 = keras.optimizers.RMSprop(lr=0.0001)\ndef pretrainedNetwork(xtrain,ytrain,xtest,ytest,pretrainedmodel,pretrainedweights,classweight,numclasses,numepochs,optimizer,labels):\n    base_model = pretrained_model_1 # Topless\n    # Add top layer\n    x = base_model.output\n    x = Flatten()(x)\n    predictions = Dense(numclasses, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    # Train top layer\n    for layer in base_model.layers:\n        layer.trainable = False\n    model.compile(loss='categorical_crossentropy', \n                  optimizer=optimizer, \n                  metrics=['accuracy'])\n    callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n    model.summary()\n    # Fit model\n    history = model.fit(xtrain,ytrain, epochs=numepochs, class_weight=classweight, validation_data=(xtest,ytest), verbose=1,callbacks = [MetricsCheckpoint('logs')])\n    # Evaluate model\n    score = model.evaluate(xtest,ytest, verbose=0)\n    print('\\nKeras CNN - accuracy:', score[1], '\\n')\n    y_pred = model.predict(xtest)\n    print('\\n', sklearn.metrics.classification_report(np.where(ytest > 0)[1], np.argmax(y_pred, axis=1), target_names=list(labels.values())), sep='') \n    Y_pred_classes = np.argmax(y_pred,axis = 1) \n    Y_true = np.argmax(ytest,axis = 1) \n    confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n    plotKerasLearningCurve()\n    plt.show()\n    plot_learning_curve(history)\n    plt.show()\n    plot_confusion_matrix(confusion_mtx, classes = list(labels.values()))\n    plt.show()\n    return model\n#pretrainedNetwork(X_train, y_trainHot, X_test, y_testHot,pretrained_model_1,weight_path1,class_weight1,2,3,optimizer1,map_characters1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"44c3544b-1d5d-4408-94ce-a8ecb89bdb20","_uuid":"8abab1928d91eda44781f0dbc194f1e80fb8586a"},"cell_type":"markdown","source":"Transfer learning w/ InceptionV3 Convolutional Network","execution_count":null},{"metadata":{"_cell_guid":"54f91c61-c425-4c17-a5f0-1944811f56cf","_uuid":"893764b26b1dbd1bf7bedbbf811e7ec029967721","trusted":true,"collapsed":true},"cell_type":"code","source":"pretrainedNetwork(X_train, y_trainHot, X_test, y_testHot,pretrained_model_2,weight_path2,class_weight1,2,3,optimizer1,map_characters1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"7f8ec99a-d1e1-4eea-adfb-2c360145b490","_uuid":"be4341dd9681e8386feebeb374f261aad0dc4f9f"},"cell_type":"markdown","source":"*Step 6: Evaluate Undersampling Strategy*","execution_count":null},{"metadata":{"_cell_guid":"a6118296-3d6e-43a7-b07b-ce3c58d61d01","_uuid":"71ac47756f79e022764c16bfc7810a0537b7d593"},"cell_type":"markdown","source":"\nEl objetivo es deshacerse de los problemas de desequilibrio de clase. El sobremuestreo con aumento de datos (por ejemplo, SMOTE) sería preferible al submuestreo, pero el submuestreo es más rápido","execution_count":null},{"metadata":{"scrolled":true,"_cell_guid":"a86b7d6e-f4d3-4c8c-9807-c92897e875a0","_uuid":"212b47546c7033f8edf8480db2eae7b6a5e39cc4","trusted":true,"collapsed":true},"cell_type":"code","source":"# # Tratar los tamaños de clase desequilibrados a continuación\n## Hacer datos 1D para los métodos de muestreo de compatibilidad\nX_trainShape = X_train.shape[1]*X_train.shape[2]*X_train.shape[3]\nX_testShape = X_test.shape[1]*X_test.shape[2]*X_test.shape[3]\nX_trainFlat = X_train.reshape(X_train.shape[0], X_trainShape)\nX_testFlat = X_test.reshape(X_test.shape[0], X_testShape)\nY_train = y_train\nY_test = y_test\n#ros = RandomOverSampler(ratio='auto')\nros = RandomUnderSampler(ratio='auto')\nX_trainRos, Y_trainRos = ros.fit_sample(X_trainFlat, Y_train)\nX_testRos, Y_testRos = ros.fit_sample(X_testFlat, Y_test)\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_trainRosHot = to_categorical(Y_trainRos, num_classes = 2)\nY_testRosHot = to_categorical(Y_testRos, num_classes = 2)\n# Make Data 2D again\nfor i in range(len(X_trainRos)):\n    height, width, channels = 150,150,3\n    X_trainRosReshaped = X_trainRos.reshape(len(X_trainRos),height,width,channels)\nfor i in range(len(X_testRos)):\n    height, width, channels = 150,150,3\n    X_testRosReshaped = X_testRos.reshape(len(X_testRos),height,width,channels)\n# Plot Label Distribution\ndfRos = pd.DataFrame()\ndfRos[\"labels\"]=Y_trainRos\nlabRos = dfRos['labels']\ndistRos = lab.value_counts()\nsns.countplot(labRos)\nprint(dict_characters)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"34ebec12-65c4-4fd8-b958-47e0b71ec6d4","_uuid":"67f4555b0de9afd8f09c2ebe0a207ef7c9b3ff3b","trusted":true,"collapsed":true},"cell_type":"code","source":"class_weight1 = class_weight.compute_class_weight('balanced', np.unique(Y_train), Y_train)\nprint(\"Old Class Weights: \",class_weight1)\nclass_weight2 = class_weight.compute_class_weight('balanced', np.unique(Y_trainRos), Y_trainRos)#BALANCEO DE DATOS\nprint(\"New Class Weights: \",class_weight2)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"915df205-6986-40dd-96be-b11f4f468556","_uuid":"ab3d217e144271dfb0551a99d192c8caa3814483"},"cell_type":"markdown","source":"*Step 7: Evaluate Final Model*","execution_count":null},{"metadata":{"_cell_guid":"80d89d7d-7838-4908-a011-b0db212708d9","_uuid":"b422b239db3775af921bb460a688caa1b991e1a4"},"cell_type":"markdown","source":"**Transferir el aprendizaje con la red convolucional VGG16**","execution_count":null},{"metadata":{"_cell_guid":"ce65ba0c-e811-4f52-86e7-5f78da2170b1","_uuid":"a247357b8fe07d683aec3cfac1ec9b506ddc4846","trusted":true,"collapsed":true},"cell_type":"code","source":"pretrainedNetwork(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_1,weight_path1,class_weight2,2,6,optimizer1,map_characters1)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f3e06981-9033-404a-98db-8ec5b2bcae1d","_uuid":"05e91fb451d5882a1ef6a1110b0d3f9f12fad9b0"},"cell_type":"markdown","source":"Transferir el aprendizaje con la red convolucional InceptionV3","execution_count":null},{"metadata":{"_cell_guid":"3aa204e6-de96-46e6-8663-2cb3bc0f119f","_uuid":"8fdce72c1fb9ddfca8e9c90dc719eb600eb169bd","trusted":true,"collapsed":true},"cell_type":"code","source":"pretrainedNetwork(X_trainRosReshaped, Y_trainRosHot, X_testRosReshaped, Y_testRosHot,pretrained_model_2,weight_path2,class_weight2,2,6,optimizer1,map_characters1)","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"_cell_guid":"e7a5b8ae-db73-4faf-ba18-cf8e4de95f3e","_uuid":"dfcda4c8cd3604ba52baa38654e9e115e745ddd5"},"cell_type":"markdown","source":"Pudimos detectar neumonía en imágenes de rayos X con una tasa de precisión de aproximadamente el 85%. ¡Excelente!","execution_count":null},{"metadata":{"_cell_guid":"19edd9f9-892d-4291-8c4f-bc09438cbd9f","_uuid":"656fc1799f43cfdf3c752cb95dd9368e7264d1a4"},"cell_type":"markdown","source":"\nPara hacer: (1) Agregar aumento de datos; (2) Añadir curva ROC; (3)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}